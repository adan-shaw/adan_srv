1.epoll 边缘出发,所有client socket设置nonblacking
  这样会导致所有recv 启用的时候，其实数据已经接收完毕了，epoll 才会发出通知，
  但是这样还是要在recv 上面弄个dontwait 比较快，可能是调用API 的流程不一样吧，
  如果设置flage=0 会慢很多
2.send 函数设置dontwait 会比较快，但是不能保证如果发送出错，就没有catch 这种错误，
  当然这种错误机会还是比较少的，如果客户端在接收数据时断开，你也管不了
  这种数据回发，仅仅是基于TCP/IP 协议的安全性，但是却没有做深入探讨
3.用一个栈将一次epoll_wait 事件中所有的accept 添加进epoll,所有的recv 事件全部压进栈，
  再将栈整个倒进任务队列，实现批量倒入
  if_event() 函数之后，再检查队列是否不为空，不为空则全部IO 线程一次放开后，
  就马上进行下一次epoll_wait
  这样的后果导致是listen pthread 跑得很快，而IO pthread 跑得很慢，
  为什么呢？
  IO 线程被启动后，第一时间也是询问队列是否不为空，使用了一次加锁，
  然后当队列不为空的时候，就调用了pop 操作，这次是memset 操作，操作时间会更长，
  加锁时间也更长，这是第二次加锁
  4个线程抢狗屎式的涌进去抢一个锁，都必然会做if_empty???
  如果不为空，则捞空，如果为空，则返回，继续等待。
  
  此时的情况是，通常NO.0 IO pthread 第一个捞空了队列，NO.1 IO pthread 什么都没有捞到
  但是到了NO.2, NO.3 pthread 的时候，他们还没开始捞任务，这listen pthread 的下一次epoll_wait又来了
  listen pthread epoll_wait 也来排队使用队列锁，这样就会产生等待（加锁等待）
  等到epoll_wait 等到了加锁使用权之后，又开始再次放开0,1,2,3 io pthread...
  
  本来这样的顺序是完美的,但是第二次epoll_wait 会让 epoll 积累更多的事件响应，
  那么此时NO.0 线程就会没那么快返回，然后sig_io=1,listen pthread 就不会理会NO.0 pthread
  转而启用NO.1 线程去捞任务，这样开始，顺序就开始乱了。
  
  当0,1,2,3 pthread 都正在使用的时候，listen pthread 什么都不做，直接进入下一次epoll_wait
  但是recv 事件会丢失吗？不会，因为socket 已经压进了队列，下次捞任务的时候也会一次全部捞出来，
  这样的话，任务队列开始产生积聚，大积聚可能会喂包一个io pthread 让其长时间不能工作，
  甚至有队列溢出的可能（当然这是非常微薄的可能）
  
  但是为有一个问题解决不了，就是线程的频繁start and stop ~~这个问题严峻吗？我不知道